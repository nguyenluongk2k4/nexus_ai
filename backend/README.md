# Backend API - Nexus AI

Backend service cho Nexus AI sá»­ dá»¥ng FastAPI, Google Gemini AI, vÃ  ChromaDB vector database.

## ğŸš€ Quick Start

### Local Development

1. **CÃ i Ä‘áº·t dependencies:**
```bash
cd backend
pip install -r requirements.txt
```

2. **Táº¡o file `.env` tá»« template:**
```bash
cp .env.example .env
```

3. **Cáº¥u hÃ¬nh `.env`:**
```env
GOOGLE_API_KEY=your_google_api_key_here
```

4. **Cháº¡y server:**
```bash
# CÃ¡ch 1: Sá»­ dá»¥ng uvicorn trá»±c tiáº¿p
uvicorn app.server:app --reload --host 0.0.0.0 --port 8000

# CÃ¡ch 2: Cháº¡y file server.py
python -m app.server

# CÃ¡ch 3: Sá»­ dá»¥ng script (tá»« root folder)
./run-dev.bat
```

5. **Test API:**
- Health check: http://localhost:8000/health
- API docs: http://localhost:8000/docs

## ğŸ“ Cáº¥u trÃºc Project

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py           # Environment configuration
â”‚   â”œâ”€â”€ server.py           # FastAPI application
â”‚   â””â”€â”€ smart_chatbot.py    # Chatbot logic with RAG
â”œâ”€â”€ chroma/                 # ChromaDB vector database
â”œâ”€â”€ .env                    # Environment variables (not in git)
â”œâ”€â”€ .env.example           # Environment template
â”œâ”€â”€ .gitignore             # Git ignore rules
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ render.yaml            # Render.com config
â”œâ”€â”€ runtime.txt            # Python version
â”œâ”€â”€ Procfile               # Process file for deployment
â”œâ”€â”€ DEPLOY.md              # Deployment guide
â””â”€â”€ README.md              # This file
```

## ğŸ”§ Environment Variables

Xem file `.env.example` Ä‘á»ƒ biáº¿t táº¥t cáº£ cÃ¡c biáº¿n environment:

### Required
- `GOOGLE_API_KEY` - Google Gemini API key

### Optional
- `HOST` - Server host (default: 0.0.0.0)
- `PORT` - Server port (default: 8000)
- `CORS_ORIGINS` - Allowed origins (default: localhost:3000,localhost:5173)
- `INTELLIGENT_DB_PATH` - ChromaDB path (default: ./chroma)
- `INTELLIGENT_COLLECTION` - Collection name (default: ksa_project)
- `CHAT_SESSIONS_FILE` - Chat sessions file (default: smart_chat_sessions.json)
- `MAX_CONTEXT_MESSAGES` - Max context messages (default: 10)

## ğŸ“¡ API Endpoints

### REST Endpoints

#### Health Check
```http
GET /health
```
Response:
```json
{
  "status": "ok"
}
```

#### Create New Session
```http
POST /session/new
```
Response:
```json
{
  "session_id": "session_20231109_143022"
}
```

### WebSocket Endpoint

#### Chat WebSocket
```
WS /ws
```

**Message Types:**

1. **Ping/Pong:**
```json
// Send
{"type": "ping"}

// Receive
{"type": "pong"}
```

2. **New Session:**
```json
// Send
{"type": "new_session"}

// Receive
{
  "type": "session_started",
  "session_id": "session_20231109_143022"
}
```

3. **User Message:**
```json
// Send
{
  "type": "user_message",
  "text": "What is Python?",
  "session_id": "session_20231109_143022"
}

// Receive (thinking status)
{
  "type": "status",
  "status": "thinking",
  "session_id": "session_20231109_143022"
}

// Receive (bot response)
{
  "type": "bot_message",
  "text": "Python is a high-level programming language...",
  "session_id": "session_20231109_143022"
}

// Receive (idle status)
{
  "type": "status",
  "status": "idle",
  "session_id": "session_20231109_143022"
}
```

4. **Error:**
```json
{
  "type": "error",
  "error": "error_code",
  "message": "Error description",
  "session_id": "session_20231109_143022"
}
```

## ğŸ§  Smart Chatbot Features

### RAG (Retrieval Augmented Generation)
- Sá»­ dá»¥ng ChromaDB Ä‘á»ƒ lÆ°u trá»¯ vÃ  tÃ¬m kiáº¿m documents
- Embedding model: `paraphrase-multilingual-mpnet-base-v2`
- Cosine similarity search

### Memory Management
- Session-based conversation history
- Context window: 10 messages
- Persistent storage in JSON file

### AI Model
- Google Gemini 2.5 Flash
- Vietnamese language support
- Markdown formatted responses

## ğŸš€ Deployment

Xem file [DEPLOY.md](./DEPLOY.md) Ä‘á»ƒ biáº¿t chi tiáº¿t vá» deployment lÃªn Render.com

### Quick Deploy to Render.com

1. Push code to GitHub
2. Connect GitHub repo to Render
3. Configure environment variables
4. Deploy!

URL: `https://your-service.onrender.com`

## ğŸ“¦ Dependencies

Main libraries:
- **FastAPI** - Web framework
- **Uvicorn** - ASGI server
- **ChromaDB** - Vector database
- **Google Generative AI** - LLM
- **Sentence Transformers** - Embeddings
- **PyTorch** - ML framework
- **python-dotenv** - Environment management

See `requirements.txt` for full list.

## ğŸ› Troubleshooting

### ChromaDB not found
```bash
# Ensure database exists
ls -la chroma/

# Recreate database (if you have ingest script)
python ingest.py
```

### Import errors
```bash
# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

### CORS errors
- Check `CORS_ORIGINS` in `.env`
- Ensure frontend URL is included

### Port already in use
```bash
# Change port in .env
PORT=8001

# Or kill process
# Windows
netstat -ano | findstr :8000
taskkill /PID <PID> /F

# Linux/Mac
lsof -ti:8000 | xargs kill -9
```

## ğŸ› ï¸ Tech Stack

- **FastAPI** - Modern web framework
- **Google Gemini AI** - Large language model
- **ChromaDB** - Vector database
- **Sentence Transformers** - Embeddings
- **Uvicorn** - ASGI server
